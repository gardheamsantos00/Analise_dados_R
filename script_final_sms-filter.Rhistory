install.packages ("lmtest")
install.packages ("BSDA")
install.packages ("agricolae")
install.packages ("car")
install.packages("tm")
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("e1071")
install.packages("e1071")
install.packages("gmodels")
library(tm)
library(SnowballC)
library(wordcloud)
library(e1071)
library(gmodels)
sms_df <- read.csv("sms_spam.csv",stringsAsFactors=FALSE)
sms_df <- read.csv("sms_spam.csv",stringsAsFactors=FALSE)
getwd()
setwd( "C:/Users/Aluno/Documents/Rnapratica")
sms_df <- read.csv("sms_spam.csv",stringsAsFactors=FALSE)
sms_df$type <- factor(sms_df$type)
table(sms_df$type)
sms_corpus <- Vcorpus(VectorSource(sms_df$text)) #cria colecao CORPUS pra mineracao da base
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_df$text)) #cria colecao CORPUS pra mineracao da base
print(sms_corpus)
sms_corpus_clean <- tm_map(sms_corpus,content_transformer(tolowe)) #aplica metodo de limpeza e converte para minusculo
sms_corpus_clean <- tm_map(sms_corpus,content_transformer(tolower)) #aplica metodo de limpeza e converte para minusculo
sms_corpus_clean <- tm_map(sms_corpus_clean,removeNumbers) #aplica limpeza e remove numeros
stopwords()
sms_corpus_clean <- tm_map(sms_corpus_clean,removeWords,stopwords()) #remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean,removePunctuation) #remove pontuacao
sms_corpus_clean <- tm_map(sms_corpus_clean,stripWhitespace) #remove espacos extra em branco
wordStem(c("learn","learned","learning","learns")) #indica sufixo para remover
sms_corpus_clean <- tm_map(sms_corpus_clean,stemDocument) #remove sufixos
lapply(sms_corpus[1:3],as.character) #comparando bases
lapply(sms_corpus_clean[1:3],as.character) #comparando bases
wordcloud(sms_corpus_clean,min.freq =50, random,order = FALSE, colors=brewer,pal(8,"BrBG")) #vizualizar palavras na base
wordcloud(sms_corpus_clean,min.freq =50, random,order = FALSE, colors=brewer.pal(8,"BrBG")) #vizualizar palavras na base
wordcloud(sms_corpus_clean,min.freq =50, random.order = FALSE, colors=brewer.pal(8,"BrBG")) #vizualizar palavras na base
spam <- subset(sms_df,type == "spam")
ham <- subset(sms_df,type == "ham") #classifica em nao spam
wordcloud(spam$text,max.words = 50) 
wordcloud(sms_corpus_clean,min.freq =50, random.order = FALSE, colors=brewer.pal(8,"BrBG")) #vizualizar palavras na base
wordcloud(spam$text,max.words = 50) 
sms_dtm <- DocumentTermMatrix(sms_corpus_clean) #cria matriz de termos em documentos
inspect(sms_dtm[1:4,30:35]) #verificando conteudo da matriz
sms_dtm_train <- sms_dtm[1:4169] #criar base teste e treinamento
sms_dtm_test <- sms_dtm[4170:5559]#base teste e treinamento
sms_train_labels <- sms_df[1:4169,]$type
sms_test_labels <- sms_df[4170:5559,]$type
spam <-subset(sms_raw_train, type == "spam") #separa base em spam
spam <-subset(sms_dtm_train,type = "spam") #separa base em spam
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train,0.999) #elimina palavras cm baixa incidencia
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train,0.999)
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train,0.999)
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train,0.999) #elimina palavras cm baixa incidencia
sms_dtm_train <- sms_dtm[1:4169] #criar base teste e treinamento
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train,0.999)
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
sms_dtm_train <- sms_dtm[1:4169] #criar base teste e treinamento
sms_dtm_train <- sms_dtm[1:4169,] #criar base teste e treinamento
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train,0.999) #elimina palavras cm baixa incidencia
sms_freq_words <- findFreqTerms(sms_dtm_train,5)
str(sms_freq_words)
sms_dtm_freq_train <- sms_dtm_train[,sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[,sms_freq_words]
sms_dtm_test <- sms_dtm[4170:5559,]#base teste e treinamento
sms_dtm_freq_test <- sms_dtm_test[,sms_freq_words]
convert_counts <- function(x){; x <- ifelse(x > 0, "Yes", "No"); }
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2,convert_counts) #atualiza a matriz com aplicacao da funcao
sms_test <- apply(sms_dtm_freq_test, MARGIN = 2,convert_counts)
sms_classifier <- naiveBayes(sms_train,sms_train_labels) #cria um classificador naive bayes
class(sms_classifier)
sms_test_pred <- predict(sms_classifier,sms_test) #execucao do algoritmo
CrossTable(sms_test_pred,sms_test_labels,prop.chisq=FALSE,prop.t=FALSE,prop.r=FALSE,dnn=c('predicao','atual')) #analise dos resultados
